{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 05: Data Cleaning in Pandas\n",
    "\n",
    "1. Map and Apply\n",
    "2. Groupby\n",
    "3. Joining DataFrames\n",
    "4. Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `.map()` and `.apply()`\n",
    "\n",
    "These are two methods used to run functions across multiple rows/columns of your DataFrame, and there are multiple ways to use each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df = pd.read_csv('http://faculty.marshall.usc.edu/gareth-james/ISL/Auto.csv', na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### a) Broadcasting simple operations\n",
    "\n",
    "i.e. convert `year` into its full year by adding `1900` to each value (we're assuming that the year range of 70-82 is in the 1900s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df['year'] + 1900 # not destructive, we'd have to reassign the new values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### b) Boolean masking\n",
    "\n",
    "(also useful to understand this for filtering dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df[['mpg', 'cylinders', 'displacement']] # % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df['weight'] > 2800 # outputs a series of booleans\n",
    "# showing whether each value meets the condition set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use this to create new, perhaps more useful columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df['heavy'] = car_df['weight'] > 2800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### c. The `.map()` function\n",
    "\n",
    "`.map()` only works on Series, or on single columns!\n",
    "\n",
    "You can supply a condition directly into the lambda, or define specific functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df['year'].map(lambda y: y < 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tangent - for car names - let's see what names exist\n",
    "# unique(), nunique(), value_counts()\n",
    "car_df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df['name'].map(lambda n: 'ford' in n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for non-Boolean outputs, you can define a function to feed into the lambda\n",
    "\n",
    "def car_brand(value):\n",
    "    if 'ford' in value:\n",
    "        return 'Ford'\n",
    "    elif 'buick' in value:\n",
    "        return 'Buick'\n",
    "    elif 'chevrolet' in value:\n",
    "        return 'Chevrolet'\n",
    "    else:\n",
    "        return 'Other'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df['name'].map(lambda n: car_brand(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### d. The `.apply()` function\n",
    "\n",
    "This works on a DataFrame, or on multiple columns of your DataFrame.\n",
    "\n",
    "\n",
    "Before that, `applymap()`, **a different method**, is like `.map()` but you can do functions across multiple columns or on an entire DataFrame. \n",
    "\n",
    "\n",
    "i.e. turning all your data into strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df.applymap(lambda value: str(value)) # ['displacement']\n",
    "\n",
    "# remember this isn't destructive until you reassign it to the variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`.apply()` allows us to perform specific functions that take different columns as inputs. For example, if we want to engineer a new variable that's some combination of other variables. I usually define the function I want to use in `.apply()` taking in a row as its argument.\n",
    "\n",
    "\n",
    "Let's create a variable that finds the horsepower per weight of the car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def horsepower_per_weight(row):\n",
    "    return row['horsepower']/row['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df.apply(lambda r: horsepower_per_weight(r), axis=1) # axis = 1 is for columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `groupby()` methods for aggregation\n",
    "\n",
    "To get aggregated information about subsets of your data. Pretty much every time you use a groupby, you have to pair it with an aggregation function.\n",
    "\n",
    "\n",
    "Some common aggregations:\n",
    "* `.min()`: returns the minimum value for each column by group  \n",
    "* `.max()`: returns the maximum value for each column by group  \n",
    "* `.mean()`: returns the average value for each column by group  \n",
    "* `.median()`: returns the median value for each column by group  \n",
    "* `.count()`: returns the count of each column by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "car_df.groupby('cylinders').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pd.concat()` and `pd.join()`\n",
    "\n",
    "`pd.concat` stacks DataFrames together while maintaining columns or index.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                    index=[0, 1, 2, 3])\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                    index=[4, 5, 6, 7])\n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                    'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                    'C': ['C8', 'C9', 'C10', 'C11'], \n",
    "                    'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                    index=[8, 9, 10, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                    index=[2, 3, 6, 7])\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df4], join='inner', axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can supply the `join` argument to `pd.concat`, but Pandas also has a `.join()` method that can be used interchangably in most cases.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html#pandas.DataFrame.join\n",
    "\n",
    "\n",
    "There are 4 main types of joins: inner, left, right and outer. This is the same kind of join that SQL uses! https://www.w3schools.com/sql/sql_join.asp\n",
    "\n",
    "- An inner join only keeps the rows that have indexes in both tables.\n",
    "- Left join keeps all rows in the left table and supplements that information with info from the right table\n",
    "- Right join does the opposite of a left join\n",
    "- Outer join returns a combination of all rows\n",
    "\n",
    "Also, `pd.merge` exists: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html#pandas.DataFrame.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df4], join='outer', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.join(df4, how='left', rsuffix='4') # why do we need the rsuffix???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "Definitely read up on the different ways you can go about filling in missing data.\n",
    "\n",
    "`df.isna()`, `df.fillna()`\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.concat([df1, df4], join='outer', axis=1).drop(['B', 'D'], axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling NaNs per column\n",
    "na_values_per_column = {'A': 3, 'C': 2, 'F': 4}\n",
    "test.fillna(value=na_values_per_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 1x1s:\n",
    "\n",
    "- Attempt `Project: Data Cleaning - Lab`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
